{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2eKAbLj8aDX"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "import sys\n",
        "import requests\n",
        "import io\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "matplotlib.rcParams['figure.figsize'] = (8, 7)\n",
        "matplotlib.rcParams['axes.labelsize'] = 14\n",
        "matplotlib.rcParams['legend.fontsize'] = 14\n",
        "matplotlib.rcParams['xtick.labelsize'] = 12\n",
        "matplotlib.rcParams['ytick.labelsize'] = 12\n",
        "matplotlib.rcParams['lines.linewidth'] = 2\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data from github"
      ],
      "metadata": {
        "id": "0TIQCJ1l-DP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get('https://raw.githubusercontent.com/matt-komm/MLPrimer/main/data.npz')\n",
        "response.raise_for_status()\n",
        "data = np.load(io.BytesIO(response.content))"
      ],
      "metadata": {
        "id": "QGreM1II9E5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract feature arrays from loaded data. Stack features into single array of dimension `[<#samples>,<#features>]` for ML training."
      ],
      "metadata": {
        "id": "wc4dT_oE-Msv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = [\n",
        "    'jet_pt','jet_eta','jet_nparticles','jet_sdmass',\n",
        "    'jet_tau1','jet_tau2','jet_tau3','jet_tau4',\n",
        "    'jet_charge'\n",
        "]\n",
        "\n",
        "jet_features = np.stack([data[name] for name in feature_names], axis=1)\n",
        "\n",
        "jet_imgs = data['jet_img']\n",
        "\n",
        "label_names = ['Wqq','Zqq','Tbqq']\n",
        "jet_labels = np.sum([i*(data['label_'+name]>0) for i,name in enumerate(label_names)],axis=0)\n",
        "\n",
        "print ('Jet features: ',jet_features.shape)\n",
        "print ('Jet images: ',jet_imgs.shape)\n",
        "print ('Jet labels: ',jet_labels.shape)\n"
      ],
      "metadata": {
        "id": "rNKGDfjA9OWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot feature distributions"
      ],
      "metadata": {
        "id": "q1WQcsbR-smk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[12,12])\n",
        "for i,feature in enumerate(feature_names):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    _,bins,_ = plt.hist(data[feature][data['label_Tbqq']>0],bins=25,alpha=0.5,label='Wqq')\n",
        "    plt.hist(data[feature][data['label_Zqq']>0],bins=bins,alpha=0.5,label='Zqq')\n",
        "    plt.hist(data[feature][data['label_Wqq']>0],bins=bins,alpha=0.5,label='Tbqq')\n",
        "    plt.xlabel(feature)\n",
        "    plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QtAtQQxn-Bky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split randomly into train and test samples"
      ],
      "metadata": {
        "id": "pW9EVFL_CYNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.model_selection\n",
        "\n",
        "jet_feature_train, jet_feature_test, jet_img_train, jet_img_test, label_train, label_test = \\\n",
        "    sklearn.model_selection.train_test_split(jet_features, jet_imgs, jet_labels, test_size=0.33, random_state=42)\n",
        "\n",
        "print ('Split jet features: ',jet_feature_train.shape,jet_feature_test.shape)\n",
        "print ('Split jet images: ',jet_img_train.shape,jet_img_test.shape)\n",
        "print ('Split jet labels: ',label_train.shape,label_test.shape)\n"
      ],
      "metadata": {
        "id": "wbJ9t4GW-u3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a BDT"
      ],
      "metadata": {
        "id": "3jT4qk82Cd1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "bdt = HistGradientBoostingClassifier(\n",
        "    max_iter=100,\n",
        "    learning_rate=0.2,\n",
        "    max_depth=8,\n",
        "    #max_depth=3,\n",
        "    #min_samples_leaf=2000,\n",
        "    random_state=42,\n",
        "    verbose=1,\n",
        "    early_stopping=False,\n",
        ")\n",
        "bdt.fit(jet_feature_train, label_train)"
      ],
      "metadata": {
        "id": "k7Rn--SLCcH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot loss vs iteration"
      ],
      "metadata": {
        "id": "PIUV_t_LCpW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bdt_scores_train = bdt.predict_proba(jet_feature_train)\n",
        "bdt_scores_test = bdt.predict_proba(jet_feature_test)\n",
        "\n",
        "def get_loss_vs_iteration(x_features, y_labels, classifier):\n",
        "    return np.array(list(map(\n",
        "        lambda score: sklearn.metrics.log_loss(y_labels,score), classifier.staged_predict_proba(x_features)\n",
        "    )))\n",
        "\n",
        "train_loss_bdt = get_loss_vs_iteration(jet_feature_train, label_train, bdt)\n",
        "test_loss_bdt = get_loss_vs_iteration(jet_feature_test, label_test, bdt)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(len(train_loss_bdt)),train_loss_bdt,label=\"BDT (train)\",color='royalblue',linestyle='-')\n",
        "plt.plot(np.arange(len(test_loss_bdt)),test_loss_bdt,label=\"BDT (test)\",color='blue',linestyle='--')\n",
        "\n",
        "plt.ylabel(\"log(loss)\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "uLNHVCrOChaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot BDT output scores"
      ],
      "metadata": {
        "id": "RhF_gzW6HNQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[12,4])\n",
        "for ilabel in range(3):\n",
        "    plt.subplot(1, 3, ilabel+1)\n",
        "    _,bins,_ = plt.hist(bdt_scores_train[label_train==0,ilabel],bins=25,alpha=0.5,label='Wqq',color='royalblue',density=True)\n",
        "    plt.hist(bdt_scores_train[label_train==1,ilabel],bins=bins,alpha=0.5,label='Zqq',color='limegreen',density=True)\n",
        "    plt.hist(bdt_scores_train[label_train==2,ilabel],bins=bins,alpha=0.5,label='Tbqq',color='darkorange',density=True)\n",
        "\n",
        "    plt.hist(bdt_scores_test[label_test==0,ilabel],bins=bins,color='blue',histtype='step',density=True)\n",
        "    plt.hist(bdt_scores_test[label_test==1,ilabel],bins=bins,histtype='step',color='darkgreen',density=True)\n",
        "    plt.hist(bdt_scores_test[label_test==2,ilabel],bins=bins,histtype='step',color='orangered',density=True)\n",
        "\n",
        "    plt.xlabel(\"BDT score \"+label_names[ilabel])\n",
        "    plt.legend()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "hd8gxAlFF2Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Relative difference between train and test selection efficiencies"
      ],
      "metadata": {
        "id": "5X462JtRTwgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selection_thresholds = np.linspace(0.05,0.95,21)\n",
        "train_selection_eff = np.array([(np.sum(1.*(bdt_scores_train[label_train==2,2]>thres)/bdt_scores_train.shape[0])) for thres in selection_thresholds])\n",
        "test_selection_eff = np.array([(np.sum(1.*(bdt_scores_test[label_test==2,2]>thres)/bdt_scores_test.shape[0]))for thres in selection_thresholds])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(selection_thresholds,100.*(train_selection_eff/test_selection_eff-1.))\n",
        "plt.xlabel(\"BDT Tbqq selection threshold\")\n",
        "plt.ylabel(\"Tbqq train/test efficiency ratio (%)\")\n",
        "plt.grid()\n",
        "plt.ylim([-1,6])\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "CHArvHn7RGto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep neural network training with Keras+Tensorflow"
      ],
      "metadata": {
        "id": "qTRqJxHkLd-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "g8t9juFyLdgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the network"
      ],
      "metadata": {
        "id": "74Yz_YoXLk7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "tf.keras.utils.set_random_seed(42)\n",
        "\n",
        "inputLayer = tf.keras.Input(shape=jet_features.shape[1:])\n",
        "nnLayer = inputLayer\n",
        "for nodes in [64,64,64]:\n",
        "    nnLayer = tf.keras.layers.Dense(nodes, activation='selu')(nnLayer)\n",
        "    nnLayer = tf.keras.layers.Dropout(0.1)(nnLayer)\n",
        "outputLayer = tf.keras.layers.Dense(3, activation=None)(nnLayer)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=[inputLayer],outputs=[outputLayer])\n",
        "print (model.summary())"
      ],
      "metadata": {
        "id": "gDsuCnx6Cs1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure the training"
      ],
      "metadata": {
        "id": "tB11NBDQcHRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer= tf.keras.optimizers.Adam(learning_rate=2e-3),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "g6udViSzL3qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "HzU1yPzRL_44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "for feature in ['jet_pt','jet_nparticles','jet_sdmass']:\n",
        "    idx = feature_names.index(feature)\n",
        "    jet_feature_train[:,idx] = np.log(1+jet_feature_train[:,idx])\n",
        "    jet_feature_test[:,idx] = np.log(1+jet_feature_test[:,idx])\n",
        "\n",
        "scaler = sklearn.preprocessing.StandardScaler()\n",
        "jet_feature_train = scaler.fit_transform(jet_feature_train)\n",
        "jet_feature_test = scaler.transform(jet_feature_test)\n",
        "'''\n",
        "\n",
        "def step_decay(epoch):\n",
        "    initial_lrate = 3e-2\n",
        "    drop = 0.7\n",
        "    epochs_drop = 10.0\n",
        "    lrate = initial_lrate * math.pow(drop, (1.+epoch)/epochs_drop)\n",
        "    return lrate\n",
        "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
        "\n",
        "\n",
        "trainProgress = model.fit(\n",
        "    x=[jet_feature_train],\n",
        "    y=[tf.keras.utils.to_categorical(label_train, num_classes = 3)],\n",
        "    batch_size=256,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    validation_split=0.25,\n",
        "    shuffle = True,\n",
        "    callbacks=[lrate]\n",
        ")"
      ],
      "metadata": {
        "id": "ge8ir7bLL7uC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare against BDT\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b_VlN2c3MSMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn_scores_train = model.predict(jet_feature_train)\n",
        "\n",
        "#note: NN outputs are logits here; need to apply softmax to get likelihoods\n",
        "nn_scores_test = tf.nn.softmax(model.predict(jet_feature_test))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(len(train_loss_bdt)),train_loss_bdt,label=\"BDT (train)\",color='royalblue',linestyle='-')\n",
        "plt.plot(np.arange(len(test_loss_bdt)),test_loss_bdt,label=\"BDT (test)\",color='blue',linestyle='--')\n",
        "plt.plot(np.arange(len(trainProgress.history['loss'])),trainProgress.history['loss'],label=\"DNN (train)\",color='lightcoral',linestyle='-')\n",
        "plt.plot(np.arange(len(trainProgress.history['val_loss'])),trainProgress.history['val_loss'],label=\"DNN (test)\",color='red',linestyle='--')\n",
        "plt.ylabel(\"log(loss)\")\n",
        "plt.xlabel(\"Iteration/Epoch\")\n",
        "plt.ylim([0.4,1.])\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "aMWOPmQBMSAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Receiver-operator-characteristic (ROC) curve"
      ],
      "metadata": {
        "id": "XZB-vigaMhtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bdt_fpr,bdt_tpr,bdt_thres = sklearn.metrics.roc_curve(label_test==2,bdt_scores_test[:,2])\n",
        "nn_fpr,nn_tpr,nn_thres = sklearn.metrics.roc_curve(label_test==2,nn_scores_test[:,2])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(bdt_tpr,bdt_fpr,color='royalblue',label='BDT test')\n",
        "plt.plot(nn_tpr,nn_fpr,color='lightcoral',linestyle='--',label='NN test')\n",
        "plt.xlabel(\"Tbqq efficiency\")\n",
        "plt.ylabel(\"Wqq+Zqq efficiency\")\n",
        "plt.grid()\n",
        "plt.xlim([0,1])\n",
        "plt.yscale('log')\n",
        "plt.ylim([1e-4,1])\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "SWxwPTm0MBVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Takeaway\n",
        "\n",
        "* BDTs have far less parameters to configure compared to DNNs\n",
        "* Overtraining reduces performance and is dangerous if reusing the training dataset\n",
        "* NNs are susceptible to widely-fluctuating inputs; preprocessing is crucial!\n",
        "* For \"simple\" tasks BDTs & DNNs can achieve similar performance when well-tuned"
      ],
      "metadata": {
        "id": "FpgUCiqHPOdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GtB4r3BKV1ba"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}