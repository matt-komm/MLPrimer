{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2eKAbLj8aDX"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "import sys\n",
        "import requests\n",
        "import io\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "matplotlib.rcParams['figure.figsize'] = (8, 7)\n",
        "matplotlib.rcParams['axes.labelsize'] = 14\n",
        "matplotlib.rcParams['legend.fontsize'] = 14\n",
        "matplotlib.rcParams['xtick.labelsize'] = 12\n",
        "matplotlib.rcParams['ytick.labelsize'] = 12\n",
        "matplotlib.rcParams['lines.linewidth'] = 2\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data from github\n",
        "\n",
        "The dataset contains simulated and reconstructed jets, ie. collimated sprays of particles, as seen in particle detectors at the CERN LHC. For each jet the following features have been saved:\n",
        "* jet kinematic properties: transverse momentum ($p_T$), pseudorapidity ($\\eta$) and mass (\"sdmass\")\n",
        "* number of clustered particles, ie. constituents (\"nparticles\")\n",
        "* substructure variables, ie. n-subjetiness, $\\tau_{N}$\n",
        "* jet charge sum from consituents\n",
        "\n",
        "The jets are preselected to originate from one of the following decays:\n",
        "* Z boson decay: $Z\\to q\\bar{q}$\n",
        "* W boson decay: $W\\to q\\bar{q}^{\\prime}$\n",
        "* Top quark decay: $t\\to bW, W\\to q\\bar{q}^{\\prime}$"
      ],
      "metadata": {
        "id": "0TIQCJ1l-DP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get('https://raw.githubusercontent.com/matt-komm/MLPrimer/main/data.npz')\n",
        "response.raise_for_status()\n",
        "data = np.load(io.BytesIO(response.content))"
      ],
      "metadata": {
        "id": "QGreM1II9E5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract feature arrays from loaded data. Stack features into single array of dimension `[<#samples>,<#features>]` for ML training."
      ],
      "metadata": {
        "id": "wc4dT_oE-Msv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = [\n",
        "    'jet_pt','jet_eta','jet_nparticles','jet_sdmass',\n",
        "    'jet_tau1','jet_tau2','jet_tau3','jet_tau4',\n",
        "    'jet_charge'\n",
        "]\n",
        "\n",
        "jet_features = np.stack([data[name] for name in feature_names], axis=1)\n",
        "\n",
        "jet_imgs = data['jet_img'][:,:,:,0:1]\n",
        "\n",
        "label_names = ['Wqq','Zqq','Tbqq']\n",
        "jet_labels = np.sum([i*(data['label_'+name]>0) for i,name in enumerate(label_names)],axis=0)\n",
        "\n",
        "print ('Jet features: ',jet_features.shape)\n",
        "print ('Jet images: ',jet_imgs.shape)\n",
        "print ('Jet labels: ',jet_labels.shape)\n"
      ],
      "metadata": {
        "id": "rNKGDfjA9OWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot feature distributions"
      ],
      "metadata": {
        "id": "q1WQcsbR-smk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[12,12])\n",
        "for i,feature in enumerate(feature_names):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    _,bins,_ = plt.hist(data[feature][data['label_Tbqq']>0],bins=25,alpha=0.5,label='Wqq')\n",
        "    plt.hist(data[feature][data['label_Zqq']>0],bins=bins,alpha=0.5,label='Zqq')\n",
        "    plt.hist(data[feature][data['label_Wqq']>0],bins=bins,alpha=0.5,label='Tbqq')\n",
        "    plt.xlabel(feature)\n",
        "    plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QtAtQQxn-Bky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split randomly into train and test samples"
      ],
      "metadata": {
        "id": "pW9EVFL_CYNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.model_selection\n",
        "\n",
        "jet_feature_train, jet_feature_test, jet_img_train, jet_img_test, label_train, label_test = \\\n",
        "    sklearn.model_selection.train_test_split(jet_features, jet_imgs, jet_labels, test_size=0.33, random_state=42)\n",
        "\n",
        "print ('Split jet features: ',jet_feature_train.shape,jet_feature_test.shape)\n",
        "print ('Split jet images: ',jet_img_train.shape,jet_img_test.shape)\n",
        "print ('Split jet labels: ',label_train.shape,label_test.shape)\n"
      ],
      "metadata": {
        "id": "wbJ9t4GW-u3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a BDT"
      ],
      "metadata": {
        "id": "3jT4qk82Cd1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "bdt = HistGradientBoostingClassifier(\n",
        "    max_iter=100,\n",
        "    learning_rate=0.2,\n",
        "    max_depth=8,\n",
        "    #max_depth=3,\n",
        "    #min_samples_leaf=2000,\n",
        "    random_state=42,\n",
        "    verbose=1,\n",
        "    early_stopping=False,\n",
        ")\n",
        "bdt.fit(jet_feature_train, label_train)"
      ],
      "metadata": {
        "id": "k7Rn--SLCcH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot loss vs iteration"
      ],
      "metadata": {
        "id": "PIUV_t_LCpW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bdt_scores_train = bdt.predict_proba(jet_feature_train)\n",
        "bdt_scores_test = bdt.predict_proba(jet_feature_test)\n",
        "\n",
        "def get_loss_vs_iteration(x_features, y_labels, classifier):\n",
        "    return np.array(list(map(\n",
        "        lambda score: sklearn.metrics.log_loss(y_labels,score), classifier.staged_predict_proba(x_features)\n",
        "    )))\n",
        "\n",
        "train_loss_bdt = get_loss_vs_iteration(jet_feature_train, label_train, bdt)\n",
        "test_loss_bdt = get_loss_vs_iteration(jet_feature_test, label_test, bdt)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(len(train_loss_bdt)),train_loss_bdt,label=\"BDT (train)\",color='royalblue',linestyle='-')\n",
        "plt.plot(np.arange(len(test_loss_bdt)),test_loss_bdt,label=\"BDT (test)\",color='blue',linestyle='--')\n",
        "\n",
        "plt.ylabel(\"log(loss)\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "uLNHVCrOChaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot BDT output scores"
      ],
      "metadata": {
        "id": "RhF_gzW6HNQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[13,4])\n",
        "for ilabel in range(3):\n",
        "    plt.subplot(1, 3, ilabel+1)\n",
        "    _,bins,_ = plt.hist(bdt_scores_train[label_train==0,ilabel],bins=25,alpha=0.5,label='Wqq',color='royalblue',density=True)\n",
        "    plt.hist(bdt_scores_train[label_train==1,ilabel],bins=bins,alpha=0.5,label='Zqq',color='limegreen',density=True)\n",
        "    plt.hist(bdt_scores_train[label_train==2,ilabel],bins=bins,alpha=0.5,label='Tbqq',color='darkorange',density=True)\n",
        "\n",
        "    plt.hist(bdt_scores_test[label_test==0,ilabel],bins=bins,color='blue',histtype='step',density=True)\n",
        "    plt.hist(bdt_scores_test[label_test==1,ilabel],bins=bins,histtype='step',color='darkgreen',density=True)\n",
        "    plt.hist(bdt_scores_test[label_test==2,ilabel],bins=bins,histtype='step',color='orangered',density=True)\n",
        "\n",
        "    plt.xlabel(\"BDT score \"+label_names[ilabel])\n",
        "    plt.legend()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "hd8gxAlFF2Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep neural network training with Keras+Tensorflow"
      ],
      "metadata": {
        "id": "qTRqJxHkLd-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "g8t9juFyLdgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the network"
      ],
      "metadata": {
        "id": "74Yz_YoXLk7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "tf.keras.utils.set_random_seed(42)\n",
        "\n",
        "inputLayer = tf.keras.Input(shape=jet_features.shape[1:])\n",
        "nnLayer = inputLayer\n",
        "for nodes in [64,64,64]:\n",
        "    nnLayer = tf.keras.layers.Dense(nodes, activation='selu')(nnLayer)\n",
        "    nnLayer = tf.keras.layers.Dropout(0.1)(nnLayer)\n",
        "outputLayer = tf.keras.layers.Dense(3, activation=None)(nnLayer)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=[inputLayer],outputs=[outputLayer])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "gDsuCnx6Cs1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure the training"
      ],
      "metadata": {
        "id": "tB11NBDQcHRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer= tf.keras.optimizers.Adam(learning_rate=2e-3),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "g6udViSzL3qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "HzU1yPzRL_44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "for feature in ['jet_pt','jet_nparticles','jet_sdmass']:\n",
        "    idx = feature_names.index(feature)\n",
        "    jet_feature_train[:,idx] = np.log(1+jet_feature_train[:,idx])\n",
        "    jet_feature_test[:,idx] = np.log(1+jet_feature_test[:,idx])\n",
        "\n",
        "scaler = sklearn.preprocessing.StandardScaler()\n",
        "jet_feature_train = scaler.fit_transform(jet_feature_train)\n",
        "jet_feature_test = scaler.transform(jet_feature_test)\n",
        "'''\n",
        "\n",
        "def step_decay(epoch):\n",
        "    initial_lrate = 3e-2\n",
        "    drop = 0.7\n",
        "    epochs_drop = 10.0\n",
        "    lrate = initial_lrate * math.pow(drop, (1.+epoch)/epochs_drop)\n",
        "    return lrate\n",
        "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
        "\n",
        "\n",
        "trainProgress = model.fit(\n",
        "    x=[jet_feature_train],\n",
        "    y=[tf.keras.utils.to_categorical(label_train, num_classes = 3)],\n",
        "    batch_size=256,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    validation_split=0.25,\n",
        "    shuffle = True,\n",
        "    callbacks=[lrate]\n",
        ")"
      ],
      "metadata": {
        "id": "ge8ir7bLL7uC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare against BDT\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b_VlN2c3MSMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn_scores_train = model.predict(jet_feature_train)\n",
        "\n",
        "#note: NN outputs are logits here; need to apply softmax to get likelihoods\n",
        "nn_scores_test = tf.nn.softmax(model.predict(jet_feature_test))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(len(train_loss_bdt)),train_loss_bdt,label=\"BDT (train)\",color='royalblue',linestyle='-')\n",
        "plt.plot(np.arange(len(test_loss_bdt)),test_loss_bdt,label=\"BDT (test)\",color='blue',linestyle='--')\n",
        "plt.plot(np.arange(len(trainProgress.history['loss'])),trainProgress.history['loss'],label=\"DNN (train)\",color='lightcoral',linestyle='-')\n",
        "plt.plot(np.arange(len(trainProgress.history['val_loss'])),trainProgress.history['val_loss'],label=\"DNN (test)\",color='red',linestyle='--')\n",
        "plt.ylabel(\"log(loss)\")\n",
        "plt.xlabel(\"Iteration/Epoch\")\n",
        "plt.ylim([0.4,1.])\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "aMWOPmQBMSAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Receiver-operator-characteristic (ROC) curve"
      ],
      "metadata": {
        "id": "XZB-vigaMhtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bdt_fpr,bdt_tpr,bdt_thres = sklearn.metrics.roc_curve(label_test==2,bdt_scores_test[:,2])\n",
        "nn_fpr,nn_tpr,nn_thres = sklearn.metrics.roc_curve(label_test==2,nn_scores_test[:,2])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(bdt_tpr,bdt_fpr,color='royalblue',label='BDT test')\n",
        "plt.plot(nn_tpr,nn_fpr,color='lightcoral',linestyle='--',label='NN test')\n",
        "plt.xlabel(\"Tbqq efficiency\")\n",
        "plt.ylabel(\"Wqq+Zqq efficiency\")\n",
        "plt.grid()\n",
        "plt.xlim([0,1])\n",
        "plt.yscale('log')\n",
        "plt.ylim([1e-4,1])\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "SWxwPTm0MBVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jet images"
      ],
      "metadata": {
        "id": "b0YDBmOop080"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imageScaler = sklearn.preprocessing.StandardScaler()\n",
        "jet_img_train = imageScaler.fit_transform(jet_img_train.reshape(jet_img_train.shape[0],-1)).reshape(jet_img_train.shape)\n",
        "jet_img_test = imageScaler.transform(jet_img_test.reshape(jet_img_test.shape[0],-1)).reshape(jet_img_test.shape)\n",
        "\n",
        "plt.figure(figsize=[11,4])\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Pixel mean\")\n",
        "plt.imshow(imageScaler.mean_.reshape(jet_img_train.shape[1:]), extent=(-0.8, 0.8, -0.8, 0.8), cmap='seismic')\n",
        "plt.ylabel(\"$\\Delta\\eta$\")\n",
        "plt.xlabel(\"$\\Delta\\phi$\")\n",
        "plt.colorbar()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Pixel scale\")\n",
        "plt.imshow(imageScaler.scale_.reshape(jet_img_train.shape[1:]), extent=(-0.8, 0.8, -0.8, 0.8), cmap='seismic')\n",
        "plt.ylabel(\"$\\Delta\\eta$\")\n",
        "plt.xlabel(\"$\\Delta\\phi$\")\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "uArppTGQwlJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[15,4])\n",
        "for ilabel in range(3):\n",
        "    plt.subplot(1, 3, ilabel+1)\n",
        "    plt.title(label_names[ilabel])\n",
        "    plt.imshow(np.mean(jet_img_train[label_train==ilabel],axis=0), extent=(-0.8, 0.8, -0.8, 0.8))#, vmin=-0.25, vmax=0.25, cmap='seismic')\n",
        "    plt.ylabel(\"$\\Delta\\eta$\")\n",
        "    plt.xlabel(\"$\\Delta\\phi$\")\n",
        "    plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "ScQDjyulp0Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "tf.keras.utils.set_random_seed(42)\n",
        "\n",
        "inputFeatureLayer = tf.keras.Input(shape=jet_features.shape[1:])\n",
        "inputImageLayer = tf.keras.Input(shape=jet_imgs.shape[1:])\n",
        "\n",
        "convLayer = inputImageLayer\n",
        "for filter,kernel in [(32,4),(16,2),(16,2),(16,2)]:\n",
        "    convLayer = tf.keras.layers.Conv2D(filter,kernel, activation='selu', padding='same')(convLayer)\n",
        "    convLayer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same')(convLayer)\n",
        "    convLayer = tf.keras.layers.Dropout(0.3)(convLayer)\n",
        "convLayer = tf.keras.layers.Flatten()(convLayer)\n",
        "\n",
        "nnLayer = tf.keras.layers.Concatenate()([convLayer,inputFeatureLayer])\n",
        "for nodes in [64,64,64]:\n",
        "    nnLayer = tf.keras.layers.Dense(nodes, activation='selu')(nnLayer)\n",
        "    nnLayer = tf.keras.layers.Dropout(0.1)(nnLayer)\n",
        "outputLayer = tf.keras.layers.Dense(3, activation=None)(nnLayer)\n",
        "\n",
        "convModel = tf.keras.models.Model(inputs=[inputFeatureLayer,inputImageLayer],outputs=[outputLayer])\n",
        "convModel.summary()"
      ],
      "metadata": {
        "id": "HQG9d51DsEbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convModel.compile(\n",
        "    optimizer= tf.keras.optimizers.Adam(learning_rate=2e-3),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "trainProgressConv = convModel.fit(\n",
        "    x=[jet_feature_train, jet_img_train],\n",
        "    y=[tf.keras.utils.to_categorical(label_train, num_classes = 3)],\n",
        "    batch_size=256,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    validation_split=0.25,\n",
        "    shuffle = True,\n",
        "    callbacks=[lrate]\n",
        ")"
      ],
      "metadata": {
        "id": "-HViI_7xsMlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(np.arange(len(train_loss_bdt)),train_loss_bdt,label=\"BDT (train)\",color='royalblue',linestyle='-')\n",
        "plt.plot(np.arange(len(test_loss_bdt)),test_loss_bdt,label=\"BDT (test)\",color='blue',linestyle='--')\n",
        "plt.plot(np.arange(len(trainProgress.history['loss'])),trainProgress.history['loss'],label=\"DNN (train)\",color='lightcoral',linestyle='-')\n",
        "plt.plot(np.arange(len(trainProgress.history['val_loss'])),trainProgress.history['val_loss'],label=\"DNN (test)\",color='red',linestyle='--')\n",
        "plt.plot(np.arange(len(trainProgressConv.history['loss'])),trainProgressConv.history['loss'],label=\"Conv (train)\",color='forestgreen',linestyle='-')\n",
        "plt.plot(np.arange(len(trainProgressConv.history['val_loss'])),trainProgressConv.history['val_loss'],label=\"Conv (test)\",color='darkgreen',linestyle='--')\n",
        "plt.ylabel(\"log(loss)\")\n",
        "plt.xlabel(\"Iteration/Epoch\")\n",
        "plt.ylim([0.4,1.])\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "BNK40hs17loi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_scores_test = tf.nn.softmax(convModel.predict([jet_feature_test,jet_img_test]))"
      ],
      "metadata": {
        "id": "k0KFuKB75F7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bdt_fpr,bdt_tpr,bdt_thres = sklearn.metrics.roc_curve(label_test==2,bdt_scores_test[:,2])\n",
        "nn_fpr,nn_tpr,nn_thres = sklearn.metrics.roc_curve(label_test==2,nn_scores_test[:,2])\n",
        "conv_fpr,conv_tpr,conv_thres = sklearn.metrics.roc_curve(label_test==2,conv_scores_test[:,2])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(bdt_tpr,bdt_fpr,color='royalblue',label='BDT test')\n",
        "plt.plot(nn_tpr,nn_fpr,color='lightcoral',linestyle='--',label='NN test')\n",
        "plt.plot(conv_tpr,conv_fpr,color='forestgreen',linestyle='--',label='Conv test')\n",
        "plt.xlabel(\"Tbqq efficiency\")\n",
        "plt.ylabel(\"Wqq+Zqq efficiency\")\n",
        "plt.grid()\n",
        "plt.xlim([0,1])\n",
        "plt.yscale('log')\n",
        "plt.ylim([1e-4,1])\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "C4usoexC46nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Takeaway\n",
        "\n",
        "* BDTs have far less parameters to configure compared to DNNs\n",
        "* Overtraining reduces performance and is dangerous if reusing the training dataset\n",
        "* NNs are susceptible to widely-fluctuating inputs; preprocessing is crucial!\n",
        "* For \"simple\" tasks BDTs & DNNs can achieve similar performance when well-tuned\n",
        "* NNs can \"easily\" be extended to handle advanced data formats, eg. images; not possible with BDTs!"
      ],
      "metadata": {
        "id": "FpgUCiqHPOdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GtB4r3BKV1ba"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}